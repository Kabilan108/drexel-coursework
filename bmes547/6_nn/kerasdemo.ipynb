{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "In this tutorial, we'll use the Pima Indians onset of diabetes dataset from the\n",
    "UCI machine learning repository. Ir describes patient medical record data for\n",
    "Pima Indians and whether they had an onset of diabetes within five years.\n",
    "\n",
    "It is a binary classification problem (onset of diabetes as 1 or not as 0).\n",
    "All of the input variables that describes each patient aren't numeric. This\n",
    "makes it easy to use directly with neural networks that expect numerical\n",
    "input and output values and is an ideal choice for our first neural network\n",
    "in keras.\n",
    "\n",
    "The data is available here:\n",
    "\n",
    "- [Dataset CSV file (pima-indians-diabetes.csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv)\n",
    "- [Dataset details](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 12:05:13.507166: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-24 12:05:14.467670: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/home/muaddib/.conda/envs/keras/lib/:/home/muaddib/.conda/envs/keras/lib/\n",
      "2023-02-24 12:05:14.467769: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/home/muaddib/.conda/envs/keras/lib/:/home/muaddib/.conda/envs/keras/lib/\n",
      "2023-02-24 12:05:14.467779: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from infoml import utils\n",
    "import numpy as np\n",
    "\n",
    "# Download the dataset\n",
    "dfile = utils.downloadurl('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are eight input variables and one output variable (the last column). You will be learning a model to map rows of input variables (X) to an output variable (y), which is often summarized as y = f(X).\n",
    "\n",
    "The variables can be summarized as follows:\n",
    "\n",
    "Input Variables (X):\n",
    "\n",
    "Number of times pregnant\n",
    "Plasma glucose concentration at 2 hours in an oral glucose tolerance test\n",
    "Diastolic blood pressure (mm Hg)\n",
    "Triceps skin fold thickness (mm)\n",
    "2-hour serum insulin (mu U/ml)\n",
    "Body mass index (weight in kg/(height in m)^2)\n",
    "Diabetes pedigree function\n",
    "Age (years)\n",
    "Output Variables (y):\n",
    "\n",
    "Class variable (0 or 1)\n",
    "Once the CSV file is loaded into memory, you can split the columns of data into input and output variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = np.loadtxt(dfile, delimiter=',')\n",
    "\n",
    "# split into input and output variables\n",
    "X = dataset[:, :8]\n",
    "y = dataset[:, 8]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Keras Model\n",
    "\n",
    "Models in Keras are defined as a sequence of layers.\n",
    "\n",
    "We create a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
