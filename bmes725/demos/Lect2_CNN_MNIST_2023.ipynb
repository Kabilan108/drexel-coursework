{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CNNs to Classify Hand-written Digits on MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/hl374/opt/anaconda3/lib/python3.8/site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/hl374/opt/anaconda3/lib/python3.8/site-packages (from keras) (1.22.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/hl374/opt/anaconda3/lib/python3.8/site-packages (from keras) (1.6.2)\n",
      "Requirement already satisfied: h5py in /Users/hl374/opt/anaconda3/lib/python3.8/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /Users/hl374/opt/anaconda3/lib/python3.8/site-packages (from keras) (6.0)\n",
      "Requirement already satisfied: six in /Users/hl374/opt/anaconda3/lib/python3.8/site-packages (from h5py->keras) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST comes with Keras by default, so load simply\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# let's print the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we train a CNN model, let’s build a basic Fully Connected Neural Network for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To build an image classification model using a neural network:\n",
    "\n",
    "- Flatten the input image dimensions to 1D (width pixels x height pixels)\n",
    "- Normalize the image pixel values (divide by 255)\n",
    "- One-Hot Encode the categorical column\n",
    "- Build a model architecture (Sequential) with Dense layers\n",
    "- Train the model and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #0: keras imports for the dataset and building our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #1: Flattening the images from the 28x28 pixels to 1D 784 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #2: normalizing the data to help with the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #3: One-Hot Encode the categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #4: building a linear stack of layers with the sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 19:10:46.207021: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-06 19:10:46.266772: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fba6c231b80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-06 19:10:46.266788: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# hidden layer\n",
    "model.add(Dense(100, input_shape=(784,), activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #5: Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.3803 - accuracy: 0.8946 - val_loss: 0.2119 - val_accuracy: 0.9384\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.9489 - val_loss: 0.1484 - val_accuracy: 0.9578\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9632 - val_loss: 0.1180 - val_accuracy: 0.9644\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9706 - val_loss: 0.1039 - val_accuracy: 0.9678\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0812 - accuracy: 0.9761 - val_loss: 0.0938 - val_accuracy: 0.9726\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0683 - accuracy: 0.9802 - val_loss: 0.0873 - val_accuracy: 0.9738\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0584 - accuracy: 0.9829 - val_loss: 0.0825 - val_accuracy: 0.9743\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0499 - accuracy: 0.9859 - val_loss: 0.0799 - val_accuracy: 0.9760\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0428 - accuracy: 0.9881 - val_loss: 0.0759 - val_accuracy: 0.9773\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0373 - accuracy: 0.9900 - val_loss: 0.0745 - val_accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fba52cfa7c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the model summary\n",
    "model.summary()\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "# training the model for 10 epochs\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let’s modify the above code to build a CNN model \n",
    "One major advantage of using CNNs over NNs is that you do not need to flatten the input images to 1D as they are capable of working with image data in 2D. This helps in retaining the “spatial” properties of images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.2006 - accuracy: 0.9401 - val_loss: 0.0757 - val_accuracy: 0.9766\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.0607 - accuracy: 0.9823 - val_loss: 0.0589 - val_accuracy: 0.9823\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0383 - accuracy: 0.9886 - val_loss: 0.0527 - val_accuracy: 0.9840\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0258 - accuracy: 0.9918 - val_loss: 0.0507 - val_accuracy: 0.9845\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0524 - val_accuracy: 0.9836\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.0632 - val_accuracy: 0.9823\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0587 - val_accuracy: 0.9840\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0551 - val_accuracy: 0.9842\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0744 - val_accuracy: 0.9808\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0631 - val_accuracy: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fba42c343d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras imports for the dataset and building our neural network\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# to calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# building the input vector from the 28x28 pixels\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)\n",
    "\n",
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "\n",
    "* Simple neural network model was around 94% (82%), the CNN model is able to get 98%+ with just a single convolution layer\n",
    "* You can go ahead and add more Conv2D layers, and also play around with the hyperparameters of the CNN model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO-DO \n",
    "1. Try to visulize images\n",
    "\n",
    "2. Try to classfiy images from the CIFAR-10 Dataset using CNNs https://www.cs.toronto.edu/~kriz/cifar.html. \n",
    "The CIFAR-10 dataset consists of 60,000 32 x 32 colour images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images.\n",
    "\n",
    "3. Try to Categorize the Images of ImageNet using CNNs (http://www.image-net.org/). The ImageNet dataset has more than 14 million images, hand-labeled across 20,000 categories.\n",
    "\n",
    "4. Try to track learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
